{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8f22f38-77db-44e3-bd11-78ec0a690f4c",
   "metadata": {},
   "source": [
    "# Classification Evaluation\n",
    "\n",
    "<img alt=\"Confusion Matrix\" src=\"./confusion-matrix.png\" width=\"400\" /> <img alt=\"Confusion Matrix Example\" src=\"./confusion-matrix-example.png\" width=\"400\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "835a13e7-9117-4aa2-a066-3361cbdc0ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 100 | FP:  42 | -> pp: 142\n",
      "FN:   8 | TN: 300 | -> pn: 308\n",
      "rp: 108 | rn: 342\n"
     ]
    }
   ],
   "source": [
    "TP = 100\n",
    "FP = 42\n",
    "FN = 8\n",
    "TN = 300\n",
    "rp = TP + FN\n",
    "rn = FP + TN\n",
    "pp = TP + FP\n",
    "pn = FN + TN\n",
    "print(f'TP: {TP:>3} | FP: {FP:>3} | -> pp: {pp:>3}')\n",
    "print(f'FN: {FN:>3} | TN: {TN:>3} | -> pn: {pn:>3}')\n",
    "print(f'rp: {rp:>3} | rn: {rn:>3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89de7ce2-2630-407f-8142-91e47e6eb30c",
   "metadata": {},
   "source": [
    "## Correct Classification Rate (CCR)\n",
    "\n",
    "Also known as **Accuracy**.\n",
    "\n",
    "It is the percentage of accurate predictions over the total of all predictions. This measure is only useful in cases where the classes are balanced.\n",
    "\n",
    "Eg: Email spam detection. Here False-positive occurs when the mail which is not spam is predicted as spam, and the user loses important information.\n",
    "\n",
    "$$CCR = \\frac{TP + TN}{rp + rn} = \\frac{TP + TN}{pp + pn} = \\frac{TP + TN}{TP + TN + FP + FN}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45757ff8-7256-421c-987f-4d5cada6479b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCR: 88.89%\n"
     ]
    }
   ],
   "source": [
    "CCR = (TP + TN) / (TP + TN + FP + FN)\n",
    "print(f'CCR: {CCR * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48148500-bf6d-427f-9f8a-4359bb97f7ff",
   "metadata": {},
   "source": [
    "## Incorrect Classification Rate (ICR)\n",
    "\n",
    "Also known as **Inverse Accuracy**.\n",
    "\n",
    "It is the percentage of inaccurate predictions over the total of all predictions. This measure is only useful in cases where the classes are balanced.\n",
    "\n",
    "$$ICR = 1 - CCR = \\frac{FP + FN}{rp + rn} = \\frac{FP + FN}{pp + pn} = \\frac{FP + FN}{TP + TN + FP + FN}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf16224d-b871-4a78-b01e-ca339c2d9bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICR: 11.11%\n"
     ]
    }
   ],
   "source": [
    "ICR = (FP + FN) / (TP + TN + FP + FN)\n",
    "print(f'ICR: {ICR * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a94ed3-c563-462f-9cee-c6ee37667999",
   "metadata": {},
   "source": [
    "## Positive Predictive Value (PPV)\n",
    "\n",
    "Also known as **Precision**, **Confidence** or **True Positive Accuracy (TPA)**\n",
    "\n",
    "Denotes the proportion of Predicted Positive cases that are correctly Real Positives.\n",
    "\n",
    "True Positive Accuracy (TPA), being a measure of accuracy of Predicted Positives in contrast with the rate of discovery of Real Positives (TPR).\n",
    "\n",
    "Out of all the positive predictions, how many were actually positive? Precision always focuses on positive predictions. Precision is also called a positive predictive value. We use precision whenever the False Positive result is important.\n",
    "\n",
    "$$PPV = \\frac{TP}{pp} = \\frac{TP}{TP + FP}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61ffaf04-1ade-4bd8-a0f7-b5c72e0f471e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPV: 70.42%\n"
     ]
    }
   ],
   "source": [
    "PPV = precision = TP / pp\n",
    "print(f'PPV: {PPV * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c914815-9c6d-4a80-a0c7-af5104aad9af",
   "metadata": {},
   "source": [
    "## Negative Predictive Value (NPV)\n",
    "\n",
    "Also known as **Inverse Precision** or **True Negative Accuracy (TNA)**\n",
    "\n",
    "$$NPV = \\frac{TN}{pn} = \\frac{TN}{TN + FN}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "def15818-4685-48ec-a7dc-5f64f7908799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPV: 97.40%\n"
     ]
    }
   ],
   "source": [
    "NPV = TN / pn\n",
    "print(f'NPV: {NPV * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02d9c3b-2a34-4026-924d-f9ec0a90e7cf",
   "metadata": {},
   "source": [
    "## True Positive Rate (TPR)\n",
    "\n",
    "- Also known as  **Recall**, **Sensitivity**, **Hit Rate** or **Detection Rate**\n",
    "- It is the percentage of actual positives which are correctly identified\n",
    "- It is the coverage of the real positive being detected as positive.\n",
    "\n",
    "Out of all the actual true values, how many were correctly predicted as positive? The recall is also called sensitivity or True positive rate (TPR). Recall always focuses on the actual positives. We use recall whenever the False Negative result is important.\n",
    "\n",
    "Ex 1:\n",
    "In a COVID Test, if a person with COVID is predicted as negative, then the error is False Negative. So, the person will not get the COVID treatment, and also, there is a chance that he will spread the disease.\n",
    "\n",
    "Ex 2:\n",
    "In fire alarm systems, we can use recall because a false negative alarm is more dangerous than a false positive.\n",
    "\n",
    "$$TPR = \\frac{TP}{rp} = \\frac{TP}{TP + FN}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af114a6c-16c5-4a0d-a25d-adc07438152c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR: 92.59%\n"
     ]
    }
   ],
   "source": [
    "TPR = recall = TP / rp\n",
    "print(f'TPR: {TPR * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0481ba3a-e8ff-4adc-a675-0a335abcd7c8",
   "metadata": {},
   "source": [
    "## True Negative Rate (TNR)\n",
    "\n",
    "- Also known as **Inverse Recall**, **Specificity** or **Selectivity**\n",
    "- It is the percentage of actual negatives which are correctly identified\n",
    "\n",
    "$$TNR = \\frac{TN}{rn} = \\frac{TN}{TN + FP}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "642c39e4-750c-4cf1-a41f-e9092222ab29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TNR: 87.72%\n"
     ]
    }
   ],
   "source": [
    "TNR = TN / rn\n",
    "print(f'TNR: {TNR * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4e48f2-e2e0-475f-b832-7c71aa8caac7",
   "metadata": {},
   "source": [
    "## False Positive Rate (FPR)\n",
    "\n",
    "- Also known as **Fallout**\n",
    "- It is the percentage of misclassified negatives (incorrectly identified as positive)\n",
    "- It is the percentage of false alerts\n",
    "- It is the proportion of Real Negatives that occur as Predicted Positive (ring-ins)\n",
    "\n",
    "$$FPR = \\frac{FP}{rp} = \\frac{FP}{TP + FN}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b183c3bf-0503-4261-8897-e49920fe686c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPR: 38.89%\n"
     ]
    }
   ],
   "source": [
    "FPR = FP / rp\n",
    "print(f'FPR: {FPR * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddbf796-4baa-47c0-97ef-4471cb9e14bc",
   "metadata": {},
   "source": [
    "## False Negative Rate (FNR)\n",
    "\n",
    "- Also known as **Miss Rate**\n",
    "- It is the percentage of misclassified positives (incorrectly identified as negatives)\n",
    "- It is the proportion of Real Positives that are Predicted Negatives (false-drops)\n",
    "\n",
    "$$FNR = \\frac{FN}{rn} = \\frac{FN}{FP + TN}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8b0a06a-4a37-4b44-b657-55eb5ab75bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNR: 2.34%\n"
     ]
    }
   ],
   "source": [
    "FNR = FN / rn\n",
    "print(f'FNR: {FNR * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2877df0-7bdb-4457-951a-a0e55e3a5937",
   "metadata": {},
   "source": [
    "## F1 Score\n",
    "\n",
    "It is the harmonic mean of precision and recall\n",
    "\n",
    "$$F1 = 2 * \\frac{Precision * Recall}{Precision + Recall} = 2 * \\frac{PPV * TPR}{PPV + TPR}$$\n",
    "\n",
    "given\n",
    "\n",
    "$$PPV = \\frac{TP}{pp} = \\frac{TP}{TP + FP}$$\n",
    "$$TPR = \\frac{TP}{rp} = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "we have\n",
    "\n",
    "$$F1 = 2 * \\frac{\\frac{TP}{TP + FP} * \\frac{TP}{TP + FN}}{\\frac{TP}{TP + FP} + \\frac{TP}{TP + FN}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e68d3b39-7252-49bb-bffa-10aa40e4999c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7999999999999999"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1 = 2 * (precision * recall) / (precision + recall)\n",
    "F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa96282b-c7c7-4c98-96c1-174a94bddbca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7999999999999999"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 * (PPV * TPR) / (PPV + TPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b43e08-d955-45aa-9410-2ecfcaf559d6",
   "metadata": {},
   "source": [
    "## Intepretation of TPR, TNR, FPR, FNR\n",
    "\n",
    "- For a good model: TPR, TNR should be closer to 1 and FNR, FPR should be closer to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93f65d6-d750-4d73-83f4-2327e0e77a68",
   "metadata": {},
   "source": [
    "## Precision and Recall\n",
    "\n",
    "Neither of them captures any information about how well the model handles negative cases. **Recall** relates only to the **R+ column** and **Precision** only to the **P+ row**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcb27b5-2f49-491f-ba08-52713d1390eb",
   "metadata": {},
   "source": [
    "## References\n",
    "- https://arxiv.org/pdf/2010.16061.pdf\n",
    "- [Positive and negative predictive values](https://en.wikipedia.org/wiki/Positive_and_negative_predictive_values)\n",
    "- [Sensitivity and Specificity](https://en.wikipedia.org/wiki/Sensitivity_and_specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaac8de-4f90-4a70-afd3-2cf5e43db690",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
