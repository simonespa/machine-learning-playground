{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47a3326a-8878-4462-baa9-89f0f2d007bd",
   "metadata": {},
   "source": [
    "# Running Order\n",
    "\n",
    "- Introduction to machine learning\n",
    "  - Glossary: list terminology\n",
    "  - Topography: AI, ML, Datascience, Datamining\n",
    "  - Learn from data to achieve a task (explain data, learn and tasks)\n",
    "  - ML Classification: supervised/unsupervised, etc.\n",
    "- Introduce the process of learning and inference\n",
    "-   - Learning process\n",
    "    - Introduce model\n",
    "- Introduce the type of data\n",
    "-   - Structured (e.g. tabular)\n",
    "    - Unstructured (signals)\n",
    "    - Talk about dimensions\n",
    "\n",
    "- What does \"learning\" mean?\n",
    "  - Draw datapoints on a 2D cartesian graph\n",
    "  - Draw a function that passes through the dots\n",
    "  - Infinite functions that generate the given datapoints\n",
    "    - Interpolation\n",
    "      - Polynomial Interpolation\n",
    "      - Piecewise polynomial interpolation (a.k.a Spline Interpolation)\n",
    "        - Linear splines\n",
    "        - Cubic splines\n",
    "    - Piecewise Linear Function\n",
    "    - Simple Linear Function\n",
    "      - Benefit of using a simple function for computational purposes \n",
    "  - Introduce the equation for the linear function\n",
    "    - Visually explain the intercept and the slope\n",
    "  - Introduce Linear Regression\n",
    "    - Regression line (a.k.a. line of best fit)\n",
    "  - Introduce the concept of error and cost function\n",
    "    - Intuition of what error menas on the graph\n",
    "    - Talk about the distance between the point and the projection on the approximation function\n",
    "    - Different type of costs function\n",
    "      - Just the distance, but then there are negative numbers\n",
    "      - The absolute value\n",
    "      - The square value\n",
    "  - Draw the cost function\n",
    "  - Talk about why convexity is key for optimisation\n",
    "    - Convex set: draw the shapes (circle, square, and something non convex) and show the line that joins 2 points\n",
    "    - Concept of epigraph: points\n",
    "    - Definition: a function F is convex iif its epigraph is a convex set\n",
    "    - Numerical definition: a function F is convex if the second-order derivative (F'') is greater than or equal to zero\n",
    "  - Explore the concept of momentum for non convex functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36fe6ee-1d48-4c7d-9ea4-974a618a856a",
   "metadata": {},
   "source": [
    "# Map of AI\n",
    "\n",
    "## Fundamental Math\n",
    "\n",
    "### Linear Algebra:\n",
    "- The study of linear equations\n",
    "- The study of linear systems\n",
    "- The study of vector spaces: the geometric interpretation useful when treating more than 3 dimensions.\n",
    "\n",
    "### Vector Calculus\n",
    "\n",
    "**Calculus** is the mathematics of change. It stydies how $y$ changes relative to $x$ (2D) or how $z$ and $y$ change relative to $x$, $y$ relative to $z$, etc. (3D).\n",
    "\n",
    "**Vector Calculus** is the extension of Calculus to multiple dimensions (vector spaces from linear algebra).\n",
    "\n",
    "It is important because by studying the change of the variables in each dimension, we can control the shape of the function/model. They are called \"parameters\".\n",
    "\n",
    "It also has functions that calculate the \"goodness\" (or \"fitness\") of these parameters with respect of the function. It is called \"objective function\" which we aim to optimise. It can be minimised if it is a loss function or maximised if it is a reward function.\n",
    "\n",
    "With vector calculus, we can calculate how changing the \"parameters\" affect the change of the \"error\".\n",
    "\n",
    "The process of reducing the error is called \"Learning\".\n",
    "\n",
    "### Probability\n",
    "\n",
    "### Statistics\n",
    "\n",
    "## Methods\n",
    "\n",
    "**Optimisation** is a method used to find the \"best\" solution given the initial state. Optimisation could be done by minimising or maximising. Most of the time it is costrained by a set of rules. **Machine Learning** is a subfield of optimisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae091e8-031d-48a5-bcbe-a88747faabb9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbf4f869-4abc-4cfd-a35b-31c2470d1c48",
   "metadata": {},
   "source": [
    "## Error\n",
    "\n",
    "Talk about the **Bias**, **Variance** and **Random Noise** (a.k.a. as irreducible error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92fdb99-e00e-40ff-8247-9dc8f4f7b638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
