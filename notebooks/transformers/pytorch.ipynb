{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "be72b5dd-3916-4abf-abec-bb0c506b356b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "52adad63-80d5-44f6-82df-8be5a56d5a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.14159265 -3.13844949 -3.13530633 ...  3.13530633  3.13844949\n",
      "  3.14159265] 2000\n"
     ]
    }
   ],
   "source": [
    "x = np.linspace(-math.pi, math.pi, 2000)\n",
    "print(x, len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a5abd90-7d99-46fb-a7a5-144a4f787fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.22464680e-16 -3.14315906e-03 -6.28628707e-03 ...  6.28628707e-03\n",
      "  3.14315906e-03  1.22464680e-16] 2000\n"
     ]
    }
   ],
   "source": [
    "y = np.sin(x)\n",
    "print(y, len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d603bb8d-4267-4701-b482-277fc2a27522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly initialize weights\n",
    "a = np.random.randn()\n",
    "b = np.random.randn()\n",
    "c = np.random.randn()\n",
    "d = np.random.randn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f0c68eb2-2b42-4591-9873-5c8bebf9fa57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-06"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 1e-6\n",
    "learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "97410769-fe2d-4162-a51b-82b205acf102",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 0.00440858270801138\n",
      "199 0.004408582707129541\n",
      "299 0.004408582706506351\n",
      "399 0.004408582706065909\n",
      "499 0.004408582705754598\n",
      "599 0.004408582705534542\n",
      "699 0.004408582705378983\n",
      "799 0.004408582705269006\n",
      "899 0.004408582705191252\n",
      "999 0.004408582705136274\n",
      "1099 0.004408582705097403\n",
      "1199 0.004408582705069914\n",
      "1299 0.004408582705050474\n",
      "1399 0.004408582705036729\n",
      "1499 0.004408582705027007\n",
      "1599 0.00440858270502013\n",
      "1699 0.004408582705015267\n",
      "1799 0.004408582705011827\n",
      "1899 0.004408582705009395\n",
      "1999 0.004408582705007672\n",
      "2099 0.004408582705006456\n",
      "2199 0.004408582705005594\n",
      "2299 0.004408582705004985\n",
      "2399 0.004408582705004553\n",
      "2499 0.00440858270500425\n",
      "2599 0.004408582705004035\n",
      "2699 0.00440858270500388\n",
      "2799 0.0044085827050037735\n",
      "2899 0.004408582705003697\n",
      "2999 0.0044085827050036434\n",
      "3099 0.004408582705003604\n",
      "3199 0.004408582705003578\n",
      "3299 0.0044085827050035584\n",
      "3399 0.0044085827050035446\n",
      "3499 0.004408582705003536\n",
      "3599 0.004408582705003528\n",
      "3699 0.004408582705003525\n",
      "3799 0.00440858270500352\n",
      "3899 0.0044085827050035185\n",
      "3999 0.004408582705003516\n",
      "4099 0.004408582705003516\n",
      "4199 0.004408582705003514\n",
      "4299 0.004408582705003514\n",
      "4399 0.004408582705003513\n",
      "4499 0.0044085827050035125\n",
      "4599 0.0044085827050035125\n",
      "4699 0.0044085827050035125\n",
      "4799 0.0044085827050035125\n",
      "4899 0.0044085827050035125\n",
      "4999 0.0044085827050035125\n",
      "5099 0.0044085827050035125\n",
      "5199 0.0044085827050035125\n",
      "5299 0.0044085827050035125\n",
      "5399 0.004408582705003514\n",
      "5499 0.0044085827050035125\n",
      "5599 0.0044085827050035125\n",
      "5699 0.0044085827050035125\n",
      "5799 0.0044085827050035125\n",
      "5899 0.0044085827050035125\n",
      "5999 0.0044085827050035125\n",
      "6099 0.0044085827050035125\n",
      "6199 0.0044085827050035125\n",
      "6299 0.0044085827050035125\n",
      "6399 0.0044085827050035125\n",
      "6499 0.0044085827050035125\n",
      "6599 0.0044085827050035125\n",
      "6699 0.0044085827050035125\n",
      "6799 0.0044085827050035125\n",
      "6899 0.0044085827050035125\n",
      "6999 0.0044085827050035125\n",
      "7099 0.0044085827050035125\n",
      "7199 0.0044085827050035125\n",
      "7299 0.0044085827050035125\n",
      "7399 0.0044085827050035125\n",
      "7499 0.0044085827050035125\n",
      "7599 0.0044085827050035125\n",
      "7699 0.0044085827050035125\n",
      "7799 0.0044085827050035125\n",
      "7899 0.0044085827050035125\n",
      "7999 0.0044085827050035125\n",
      "8099 0.0044085827050035125\n",
      "8199 0.0044085827050035125\n",
      "8299 0.0044085827050035125\n",
      "8399 0.0044085827050035125\n",
      "8499 0.0044085827050035125\n",
      "8599 0.004408582705003513\n",
      "8699 0.0044085827050035125\n",
      "8799 0.0044085827050035125\n",
      "8899 0.0044085827050035125\n",
      "8999 0.0044085827050035125\n",
      "9099 0.0044085827050035125\n",
      "9199 0.0044085827050035125\n",
      "9299 0.0044085827050035125\n",
      "9399 0.0044085827050035125\n",
      "9499 0.0044085827050035125\n",
      "9599 0.0044085827050035125\n",
      "9699 0.0044085827050035125\n",
      "9799 0.004408582705003513\n",
      "9899 0.0044085827050035125\n",
      "9999 0.0044085827050035125\n",
      "Result: y = -9.474407083416103e-14 + 0.8567408430738108 x + 1.634414419229027e-14 x^2 + -0.09333038904060259 x^3\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-6\n",
    "for t in range(10000):\n",
    "    # Forward pass: compute predicted y\n",
    "    # y = a + b x + c x^2 + d x^3\n",
    "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = np.square(y_pred - y).sum() / len(y_pred)\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss)\n",
    "\n",
    "    # Backprop to compute gradients of a, b, c, d with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_a = grad_y_pred.sum()\n",
    "    grad_b = (grad_y_pred * x).sum()\n",
    "    grad_c = (grad_y_pred * x ** 2).sum()\n",
    "    grad_d = (grad_y_pred * x ** 3).sum()\n",
    "\n",
    "    # Update weights\n",
    "    a -= learning_rate * grad_a\n",
    "    b -= learning_rate * grad_b\n",
    "    c -= learning_rate * grad_c\n",
    "    d -= learning_rate * grad_d\n",
    "\n",
    "print(f'Result: y = {a} + {b} x + {c} x^2 + {d} x^3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1f669e58-907a-48e0-9455-7f3e84bf4c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 1751.005859375\n",
      "199 1202.785400390625\n",
      "299 828.01220703125\n",
      "399 571.5155029296875\n",
      "499 395.7657775878906\n",
      "599 275.2059326171875\n",
      "699 192.4104461669922\n",
      "799 135.48583984375\n",
      "899 96.30436706542969\n",
      "999 69.30595397949219\n",
      "1099 50.68206787109375\n",
      "1199 37.821346282958984\n",
      "1299 28.930938720703125\n",
      "1399 22.778907775878906\n",
      "1499 18.517478942871094\n",
      "1599 15.562799453735352\n",
      "1699 13.512138366699219\n",
      "1799 12.087591171264648\n",
      "1899 11.097129821777344\n",
      "1999 10.40787124633789\n",
      "2099 9.927812576293945\n",
      "2199 9.59318733215332\n",
      "2299 9.359750747680664\n",
      "2399 9.196783065795898\n",
      "2499 9.082929611206055\n",
      "2599 9.003335952758789\n",
      "2699 8.947654724121094\n",
      "2799 8.908676147460938\n",
      "2899 8.881375312805176\n",
      "2999 8.862241744995117\n",
      "3099 8.848823547363281\n",
      "3199 8.839410781860352\n",
      "3299 8.832801818847656\n",
      "3399 8.82816219329834\n",
      "3499 8.824901580810547\n",
      "3599 8.822610855102539\n",
      "3699 8.820999145507812\n",
      "3799 8.819864273071289\n",
      "3899 8.819067001342773\n",
      "3999 8.818506240844727\n",
      "4099 8.818111419677734\n",
      "4199 8.817831993103027\n",
      "4299 8.817636489868164\n",
      "4399 8.817497253417969\n",
      "4499 8.817399978637695\n",
      "4599 8.817331314086914\n",
      "4699 8.817282676696777\n",
      "4799 8.817249298095703\n",
      "4899 8.817224502563477\n",
      "4999 8.817207336425781\n",
      "5099 8.817195892333984\n",
      "5199 8.81718635559082\n",
      "5299 8.817180633544922\n",
      "5399 8.81717586517334\n",
      "5499 8.81717300415039\n",
      "5599 8.817171096801758\n",
      "5699 8.817170143127441\n",
      "5799 8.817169189453125\n",
      "5899 8.817168235778809\n",
      "5999 8.817167282104492\n",
      "6099 8.817167282104492\n",
      "6199 8.817167282104492\n",
      "6299 8.817167282104492\n",
      "6399 8.817167282104492\n",
      "6499 8.817167282104492\n",
      "6599 8.817166328430176\n",
      "6699 8.817166328430176\n",
      "6799 8.817167282104492\n",
      "6899 8.817166328430176\n",
      "6999 8.817166328430176\n",
      "7099 8.817166328430176\n",
      "7199 8.817166328430176\n",
      "7299 8.817166328430176\n",
      "7399 8.817167282104492\n",
      "7499 8.81716537475586\n",
      "7599 8.817166328430176\n",
      "7699 8.817166328430176\n",
      "7799 8.817166328430176\n",
      "7899 8.817166328430176\n",
      "7999 8.817166328430176\n",
      "8099 8.817166328430176\n",
      "8199 8.817166328430176\n",
      "8299 8.817166328430176\n",
      "8399 8.817166328430176\n",
      "8499 8.81716537475586\n",
      "8599 8.817166328430176\n",
      "8699 8.817166328430176\n",
      "8799 8.817166328430176\n",
      "8899 8.817166328430176\n",
      "8999 8.817167282104492\n",
      "9099 8.817167282104492\n",
      "9199 8.817167282104492\n",
      "9299 8.817166328430176\n",
      "9399 8.81716537475586\n",
      "9499 8.817166328430176\n",
      "9599 8.817166328430176\n",
      "9699 8.81716537475586\n",
      "9799 8.81716537475586\n",
      "9899 8.81716537475586\n",
      "9999 8.81716537475586\n",
      "Result: y = 3.634343670455564e-08 + 0.8567265272140503 x + -1.139751315548665e-08 x^2 + -0.09332834929227829 x^3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "dtype = torch.float\n",
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"mps\") # Uncomment this to run on GPU\n",
    "\n",
    "# Create random input and output data\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# Randomly initialize weights\n",
    "a = torch.randn((), device=device, dtype=dtype)\n",
    "b = torch.randn((), device=device, dtype=dtype)\n",
    "c = torch.randn((), device=device, dtype=dtype)\n",
    "d = torch.randn((), device=device, dtype=dtype)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(10000):\n",
    "    # Forward pass: compute predicted y\n",
    "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = (y_pred - y).pow(2).sum().item()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss)\n",
    "\n",
    "    # Backprop to compute gradients of a, b, c, d with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_a = grad_y_pred.sum()\n",
    "    grad_b = (grad_y_pred * x).sum()\n",
    "    grad_c = (grad_y_pred * x ** 2).sum()\n",
    "    grad_d = (grad_y_pred * x ** 3).sum()\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    a -= learning_rate * grad_a\n",
    "    b -= learning_rate * grad_b\n",
    "    c -= learning_rate * grad_c\n",
    "    d -= learning_rate * grad_d\n",
    "\n",
    "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a07836d1-42dd-4685-85dc-ee590c6865e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor([0]) is torch.Size([1]) and dimension is 1\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.LongTensor([0])\n",
    "print(f'Shape of {tensor} is {tensor.shape} and dimension is {tensor.dim()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4ac196a9-7039-460d-92cc-065d7369ce68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor([0, 1, 2, 3]) is torch.Size([4]) and dimension is 1\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.LongTensor([0, 1, 2, 3])\n",
    "print(f'Shape of {tensor} is {tensor.shape} and dimension is {tensor.dim()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a4febd7a-9dd8-4a76-87c7-9a5465ae4695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor([[1, 2, 3],\n",
      "        [4, 5, 6]]) is torch.Size([2, 3]) and dimension is 2\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.LongTensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(f'Shape of {tensor} is {tensor.shape} and dimension is {tensor.dim()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b2a442da-a068-47e9-a76d-9d2404b2c1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor([1, 2, 3, 4]) is torch.Size([4]) and dimension is 1\n",
      "Shape of tensor([[1, 2, 3, 4]]) is torch.Size([1, 4]) and dimension is 2\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.LongTensor([1, 2, 3, 4])\n",
    "\n",
    "print(f'Shape of {tensor} is {tensor.shape} and dimension is {tensor.dim()}')\n",
    "\n",
    "tensor = tensor.unsqueeze(0)\n",
    "\n",
    "print(f'Shape of {tensor} is {tensor.shape} and dimension is {tensor.dim()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e33a0ef-f39a-4c5d-bb1f-e3b2077f6cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
