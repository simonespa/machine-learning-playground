{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be72b5dd-3916-4abf-abec-bb0c506b356b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52adad63-80d5-44f6-82df-8be5a56d5a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.14159265 -3.13844949 -3.13530633 ...  3.13530633  3.13844949\n",
      "  3.14159265] 2000\n"
     ]
    }
   ],
   "source": [
    "x = np.linspace(-math.pi, math.pi, 2000)\n",
    "print(x, len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a5abd90-7d99-46fb-a7a5-144a4f787fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.22464680e-16 -3.14315906e-03 -6.28628707e-03 ...  6.28628707e-03\n",
      "  3.14315906e-03  1.22464680e-16] 2000\n"
     ]
    }
   ],
   "source": [
    "y = np.sin(x)\n",
    "print(y, len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d603bb8d-4267-4701-b482-277fc2a27522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly initialize weights\n",
    "a = np.random.randn()\n",
    "b = np.random.randn()\n",
    "c = np.random.randn()\n",
    "d = np.random.randn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0c68eb2-2b42-4591-9873-5c8bebf9fa57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-06"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 1e-6\n",
    "learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97410769-fe2d-4162-a51b-82b205acf102",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 0.29983590720419095\n",
      "199 0.2028017640992121\n",
      "299 0.13774868694559525\n",
      "399 0.09410302961554826\n",
      "499 0.06479700576338866\n",
      "599 0.04510325638561532\n",
      "699 0.03185775408173559\n",
      "799 0.02294135160202208\n",
      "899 0.016933702827729536\n",
      "999 0.01288211603199151\n",
      "1099 0.010147079093956969\n",
      "1199 0.008298960278793921\n",
      "1299 0.007048885870143335\n",
      "1399 0.006202455731518004\n",
      "1499 0.005628729212702545\n",
      "1599 0.0052394279982829845\n",
      "1699 0.004974979421563852\n",
      "1799 0.004795142841612767\n",
      "1899 0.004672708892223826\n",
      "1999 0.004589260616302689\n",
      "2099 0.004532319215380814\n",
      "2199 0.004493420373449682\n",
      "2299 0.004466816536135376\n",
      "2399 0.004448600613214678\n",
      "2499 0.004436113662054781\n",
      "2599 0.004427544114431383\n",
      "2699 0.004421656322884857\n",
      "2799 0.004417606503025929\n",
      "2899 0.004414817799211235\n",
      "2999 0.004412895388706713\n",
      "3099 0.004411568728731464\n",
      "3199 0.004410652224040876\n",
      "3299 0.004410018409323112\n",
      "3399 0.00440957964353627\n",
      "3499 0.004409275600140953\n",
      "3599 0.004409064708311922\n",
      "3699 0.0044089182905515945\n",
      "3799 0.004408816542612603\n",
      "3899 0.00440874577362059\n",
      "3999 0.004408696509206997\n",
      "4099 0.004408662186326428\n",
      "4199 0.0044086382541997215\n",
      "4299 0.004408621554333541\n",
      "4399 0.00440860989252798\n",
      "4499 0.004408601743107352\n",
      "4599 0.004408596044313638\n",
      "4699 0.004408592056620904\n",
      "4799 0.0044085892645241405\n",
      "4899 0.004408587308397426\n",
      "4999 0.004408585937170833\n",
      "5099 0.0044085849754357306\n",
      "5199 0.004408584300559235\n",
      "5299 0.004408583826748748\n",
      "5399 0.004408583493946807\n",
      "5499 0.004408583260085967\n",
      "5599 0.004408583095682997\n",
      "5699 0.004408582980063059\n",
      "5799 0.004408582898720563\n",
      "5899 0.004408582841473244\n",
      "5999 0.004408582801170259\n",
      "6099 0.004408582772787432\n",
      "6199 0.0044085827527932915\n",
      "6299 0.004408582738704585\n",
      "6399 0.004408582728774478\n",
      "6499 0.0044085827217737305\n",
      "6599 0.004408582716837038\n",
      "6699 0.004408582713355081\n",
      "6799 0.004408582710898673\n",
      "6899 0.00440858270916542\n",
      "6999 0.004408582707942205\n",
      "7099 0.004408582707078794\n",
      "7199 0.004408582706469254\n",
      "7299 0.004408582706038871\n",
      "7399 0.004408582705734945\n",
      "7499 0.004408582705520292\n",
      "7599 0.004408582705368672\n",
      "7699 0.004408582705261559\n",
      "7799 0.004408582705185884\n",
      "7899 0.004408582705132412\n",
      "7999 0.004408582705094624\n",
      "8099 0.004408582705067919\n",
      "8199 0.004408582705049044\n",
      "8299 0.004408582705035704\n",
      "8399 0.004408582705026273\n",
      "8499 0.004408582705019606\n",
      "8599 0.004408582705014891\n",
      "8699 0.004408582705011559\n",
      "8799 0.004408582705009204\n",
      "8899 0.004408582705007537\n",
      "8999 0.004408582705006358\n",
      "9099 0.004408582705005525\n",
      "9199 0.004408582705004936\n",
      "9299 0.004408582705004519\n",
      "9399 0.004408582705004225\n",
      "9499 0.004408582705004016\n",
      "9599 0.00440858270500387\n",
      "9699 0.004408582705003765\n",
      "9799 0.00440858270500369\n",
      "9899 0.004408582705003638\n",
      "9999 0.004408582705003601\n",
      "Result: y = 1.411384938850552e-08 + 0.856740842228333 x + -2.434873875573946e-09 x^2 + -0.09333038892034075 x^3\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-6\n",
    "for t in range(10000):\n",
    "    # Forward pass: compute predicted y\n",
    "    # y = a + b x + c x^2 + d x^3\n",
    "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = np.square(y_pred - y).sum() / len(y_pred)\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss)\n",
    "\n",
    "    # Backprop to compute gradients of a, b, c, d with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_a = grad_y_pred.sum()\n",
    "    grad_b = (grad_y_pred * x).sum()\n",
    "    grad_c = (grad_y_pred * x ** 2).sum()\n",
    "    grad_d = (grad_y_pred * x ** 3).sum()\n",
    "\n",
    "    # Update weights\n",
    "    a -= learning_rate * grad_a\n",
    "    b -= learning_rate * grad_b\n",
    "    c -= learning_rate * grad_c\n",
    "    d -= learning_rate * grad_d\n",
    "\n",
    "print(f'Result: y = {a} + {b} x + {c} x^2 + {d} x^3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f669e58-907a-48e0-9455-7f3e84bf4c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 2193.87060546875\n",
      "199 1504.713623046875\n",
      "299 1034.0909423828125\n",
      "399 712.3340454101562\n",
      "499 492.1014404296875\n",
      "599 341.1858825683594\n",
      "699 237.65191650390625\n",
      "799 166.54266357421875\n",
      "899 117.64822387695312\n",
      "999 83.99083709716797\n",
      "1099 60.79669952392578\n",
      "1199 44.79568099975586\n",
      "1299 33.74520492553711\n",
      "1399 26.10565757751465\n",
      "1499 20.818702697753906\n",
      "1599 17.156208038330078\n",
      "1699 14.61654281616211\n",
      "1799 12.85383415222168\n",
      "1899 11.629206657409668\n",
      "1999 10.777692794799805\n",
      "2099 10.185089111328125\n",
      "2199 9.772317886352539\n",
      "2299 9.484577178955078\n",
      "2399 9.283838272094727\n",
      "2499 9.143692016601562\n",
      "2599 9.045774459838867\n",
      "2699 8.977315902709961\n",
      "2799 8.929421424865723\n",
      "2899 8.895893096923828\n",
      "2999 8.872407913208008\n",
      "3099 8.855947494506836\n",
      "3199 8.844404220581055\n",
      "3299 8.836305618286133\n",
      "3399 8.830620765686035\n",
      "3499 8.826627731323242\n",
      "3599 8.823822021484375\n",
      "3699 8.821849822998047\n",
      "3799 8.820463180541992\n",
      "3899 8.819488525390625\n",
      "3999 8.818803787231445\n",
      "4099 8.818320274353027\n",
      "4199 8.817980766296387\n",
      "4299 8.817739486694336\n",
      "4399 8.817569732666016\n",
      "4499 8.817451477050781\n",
      "4599 8.817367553710938\n",
      "4699 8.81730842590332\n",
      "4799 8.817267417907715\n",
      "4899 8.817237854003906\n",
      "4999 8.817216873168945\n",
      "5099 8.8172025680542\n",
      "5199 8.817192077636719\n",
      "5299 8.817184448242188\n",
      "5399 8.817178726196289\n",
      "5499 8.817174911499023\n",
      "5599 8.817172050476074\n",
      "5699 8.817171096801758\n",
      "5799 8.817169189453125\n",
      "5899 8.817169189453125\n",
      "5999 8.817168235778809\n",
      "6099 8.817167282104492\n",
      "6199 8.817166328430176\n",
      "6299 8.817167282104492\n",
      "6399 8.817166328430176\n",
      "6499 8.817166328430176\n",
      "6599 8.817166328430176\n",
      "6699 8.817167282104492\n",
      "6799 8.817166328430176\n",
      "6899 8.81716537475586\n",
      "6999 8.817166328430176\n",
      "7099 8.817166328430176\n",
      "7199 8.817166328430176\n",
      "7299 8.817166328430176\n",
      "7399 8.817166328430176\n",
      "7499 8.817167282104492\n",
      "7599 8.817166328430176\n",
      "7699 8.817166328430176\n",
      "7799 8.817166328430176\n",
      "7899 8.817166328430176\n",
      "7999 8.817166328430176\n",
      "8099 8.817166328430176\n",
      "8199 8.817166328430176\n",
      "8299 8.81716537475586\n",
      "8399 8.817166328430176\n",
      "8499 8.817166328430176\n",
      "8599 8.817166328430176\n",
      "8699 8.817166328430176\n",
      "8799 8.817166328430176\n",
      "8899 8.817166328430176\n",
      "8999 8.817166328430176\n",
      "9099 8.817166328430176\n",
      "9199 8.817166328430176\n",
      "9299 8.81716537475586\n",
      "9399 8.817166328430176\n",
      "9499 8.817166328430176\n",
      "9599 8.817166328430176\n",
      "9699 8.81716537475586\n",
      "9799 8.81716537475586\n",
      "9899 8.81716537475586\n",
      "9999 8.81716537475586\n",
      "Result: y = -3.9670421614346196e-08 + 0.8567265272140503 x + 1.1368075369944108e-08 x^2 + -0.09332834929227829 x^3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "dtype = torch.float\n",
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"mps\") # Uncomment this to run on GPU\n",
    "\n",
    "# Create random input and output data\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# Randomly initialize weights\n",
    "a = torch.randn((), device=device, dtype=dtype)\n",
    "b = torch.randn((), device=device, dtype=dtype)\n",
    "c = torch.randn((), device=device, dtype=dtype)\n",
    "d = torch.randn((), device=device, dtype=dtype)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(10000):\n",
    "    # Forward pass: compute predicted y\n",
    "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = (y_pred - y).pow(2).sum().item()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss)\n",
    "\n",
    "    # Backprop to compute gradients of a, b, c, d with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_a = grad_y_pred.sum()\n",
    "    grad_b = (grad_y_pred * x).sum()\n",
    "    grad_c = (grad_y_pred * x ** 2).sum()\n",
    "    grad_d = (grad_y_pred * x ** 3).sum()\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    a -= learning_rate * grad_a\n",
    "    b -= learning_rate * grad_b\n",
    "    c -= learning_rate * grad_c\n",
    "    d -= learning_rate * grad_d\n",
    "\n",
    "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a07836d1-42dd-4685-85dc-ee590c6865e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor([0]) is torch.Size([1]) and dimension is 1\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.LongTensor([0])\n",
    "print(f'Shape of {tensor} is {tensor.shape} and dimension is {tensor.dim()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ac196a9-7039-460d-92cc-065d7369ce68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor([0, 1, 2, 3]) is torch.Size([4]) and dimension is 1\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.LongTensor([0, 1, 2, 3])\n",
    "print(f'Shape of {tensor} is {tensor.shape} and dimension is {tensor.dim()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4febd7a-9dd8-4a76-87c7-9a5465ae4695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor([[1, 2, 3],\n",
      "        [4, 5, 6]]) is torch.Size([2, 3]) and dimension is 2\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.LongTensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(f'Shape of {tensor} is {tensor.shape} and dimension is {tensor.dim()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2a442da-a068-47e9-a76d-9d2404b2c1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor([1, 2, 3, 4]) is torch.Size([4]) and dimension is 1\n",
      "Shape of tensor([[1, 2, 3, 4]]) is torch.Size([1, 4]) and dimension is 2\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.LongTensor([1, 2, 3, 4])\n",
    "\n",
    "print(f'Shape of {tensor} is {tensor.shape} and dimension is {tensor.dim()}')\n",
    "\n",
    "tensor = tensor.unsqueeze(0)\n",
    "\n",
    "print(f'Shape of {tensor} is {tensor.shape} and dimension is {tensor.dim()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
