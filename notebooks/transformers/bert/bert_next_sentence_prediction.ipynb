{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8853b6b3-06ae-4320-b6d1-e2a0ac1388d3",
   "metadata": {},
   "source": [
    "# Next sentence prediction (NSP) task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8037136-593e-4452-b0f6-e5181ecd0f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertForNextSentencePrediction, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99f9ddf3-a52e-4953-8f2a-fc72d05a7146",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_id)\n",
    "bert_nsp = BertForNextSentencePrediction.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38cc01fa-d86b-4645-b26b-561f76bd36c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForNextSentencePrediction(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyNSPHead(\n",
       "    (seq_relationship): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_nsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f123909d-c670-450e-a802-733e7d922bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = [\n",
    "    \"A preface is an introductory section of a book, written by the author, that provides context for the reader.\",\n",
    "    \"It typically explains the book's purpose, the author's motivation for writing it, and the inspiration behind the subject matter.\"\n",
    "]\n",
    "\n",
    "text2 = [\n",
    "    'A basic math problem could be: \"If you have 5 apples and you buy 3 more, how many apples do you have?\"',\n",
    "    'A great marriage is one where each person, without agenda, celebrates the unique and distinctive characteristics of the other, and lovingly helps them be the best possible version of themselves.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96bf5b95-330f-4949-b671-394cf4132e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs1 = tokenizer(text1[0], text1[1], return_tensors='pt')\n",
    "inputs2 = tokenizer(text2[0], text2[1], return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a64850c7-ef60-4fe5-ab0e-a8902d73217a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1037, 18443,  2003,  2019, 23889,  2930,  1997,  1037,  2338,\n",
       "          1010,  2517,  2011,  1996,  3166,  1010,  2008,  3640,  6123,  2005,\n",
       "          1996,  8068,  1012,   102,  2009,  4050,  7607,  1996,  2338,  1005,\n",
       "          1055,  3800,  1010,  1996,  3166,  1005,  1055, 14354,  2005,  3015,\n",
       "          2009,  1010,  1998,  1996,  7780,  2369,  1996,  3395,  3043,  1012,\n",
       "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aec43c0e-cb5a-4d79-85fb-f5c15157a30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1037,  3937,  8785,  3291,  2071,  2022,  1024,  1000,  2065,\n",
       "          2017,  2031,  1019, 18108,  1998,  2017,  4965,  1017,  2062,  1010,\n",
       "          2129,  2116, 18108,  2079,  2017,  2031,  1029,  1000,   102,  1037,\n",
       "          2307,  3510,  2003,  2028,  2073,  2169,  2711,  1010,  2302, 11376,\n",
       "          1010, 21566,  1996,  4310,  1998,  8200,  6459,  1997,  1996,  2060,\n",
       "          1010,  1998,  8295,  2135,  7126,  2068,  2022,  1996,  2190,  2825,\n",
       "          2544,  1997,  3209,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b8f2ea8-9d34-41ce-9bd8-534add06f3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs1 = bert_nsp(**inputs1)\n",
    "outputs2 = bert_nsp(**inputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4ef555d-d6b0-4360-a854-557ae9798b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NextSentencePredictorOutput(loss=None, logits=tensor([[ 6.3702, -6.1489]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98e1b0e6-2a5d-4111-bee2-ba24fb42f65c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NextSentencePredictorOutput(loss=None, logits=tensor([[-3.2097,  6.2860]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
