{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f82d1415-45c0-4d57-a6cc-82802a2244e4",
   "metadata": {},
   "source": [
    "# distilBERT: text classification for intent detection\n",
    "\n",
    "This notebook is sourcing the data from the SNIPs dataset for intent classification. The aim is to fine-tune a pre-trained distilBERT model and classify the utterances with the following intents:\n",
    "- `AddToPlaylist`\n",
    "- `BookRestaurant`\n",
    "- `GetWeather`\n",
    "- `PlayMusic`\n",
    "- `RateBook`\n",
    "- `SearchCreativeWork`\n",
    "- `SearchScreeningEvent`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaeb07d0-bad5-4bbd-a49c-1a17e6b7379e",
   "metadata": {},
   "source": [
    "## Data loading, transformation and inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1b9ecd5-08d0-4185-a42c-289de0044c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_intents(file_name, intent_name):\n",
    "    with open(file_name, 'r') as file:\n",
    "        raw_data = json.load(file)\n",
    "    \n",
    "    return [\n",
    "        ''.join(\n",
    "            [\n",
    "                data.get('text', '') for data in intent.get('data', [])\n",
    "            ]\n",
    "        ).strip() for intent in raw_data.get(intent_name, [])\n",
    "    ]\n",
    "\n",
    "intents = [\n",
    "    'AddToPlaylist',\n",
    "    'BookRestaurant',\n",
    "    'GetWeather',\n",
    "    'PlayMusic',\n",
    "    'RateBook',\n",
    "    'SearchCreativeWork',\n",
    "    'SearchScreeningEvent'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "679f0a91-d4a6-468b-863d-97680f00bfa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AddToPlaylist</th>\n",
       "      <th>BookRestaurant</th>\n",
       "      <th>GetWeather</th>\n",
       "      <th>PlayMusic</th>\n",
       "      <th>RateBook</th>\n",
       "      <th>SearchCreativeWork</th>\n",
       "      <th>SearchScreeningEvent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>training</th>\n",
       "      <td>[add this track to my Gold School playlist, pu...</td>\n",
       "      <td>[book a party of 9 for The Wieners Circle in P...</td>\n",
       "      <td>[What's the weather in Ecola State Park in thr...</td>\n",
       "      <td>[Play me a song by Stephen Jones, play somethi...</td>\n",
       "      <td>[Rate The Removers 4 out of 6, Rate the curren...</td>\n",
       "      <td>[Can you get me The Education of Little Tree s...</td>\n",
       "      <td>[Please tell me movie times, What time is The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>[add a track in Nike Running Tempo Mix, I'd li...</td>\n",
       "      <td>[I need a table for nine at a nice restaurant ...</td>\n",
       "      <td>[What's the weather in the current place?, Wea...</td>\n",
       "      <td>[Can you play a chant by Butch Trucks on Spoti...</td>\n",
       "      <td>[I give zero points to this chronicle, The You...</td>\n",
       "      <td>[find Karol: The Pope, Search for The Long Dar...</td>\n",
       "      <td>[Find the movie schedules for animated movies ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                AddToPlaylist  \\\n",
       "training    [add this track to my Gold School playlist, pu...   \n",
       "validation  [add a track in Nike Running Tempo Mix, I'd li...   \n",
       "\n",
       "                                               BookRestaurant  \\\n",
       "training    [book a party of 9 for The Wieners Circle in P...   \n",
       "validation  [I need a table for nine at a nice restaurant ...   \n",
       "\n",
       "                                                   GetWeather  \\\n",
       "training    [What's the weather in Ecola State Park in thr...   \n",
       "validation  [What's the weather in the current place?, Wea...   \n",
       "\n",
       "                                                    PlayMusic  \\\n",
       "training    [Play me a song by Stephen Jones, play somethi...   \n",
       "validation  [Can you play a chant by Butch Trucks on Spoti...   \n",
       "\n",
       "                                                     RateBook  \\\n",
       "training    [Rate The Removers 4 out of 6, Rate the curren...   \n",
       "validation  [I give zero points to this chronicle, The You...   \n",
       "\n",
       "                                           SearchCreativeWork  \\\n",
       "training    [Can you get me The Education of Little Tree s...   \n",
       "validation  [find Karol: The Pope, Search for The Long Dar...   \n",
       "\n",
       "                                         SearchScreeningEvent  \n",
       "training    [Please tell me movie times, What time is The ...  \n",
       "validation  [Find the movie schedules for animated movies ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from random import shuffle\n",
    "\n",
    "dataset = {}\n",
    "\n",
    "for intent in intents:\n",
    "    intents_list = list(set(\n",
    "        load_intents(f'data/custom-intent-engines/{intent}/train_{intent}_full.json', intent)\n",
    "    ).union(\n",
    "        load_intents(f'data/custom-intent-engines/{intent}/train_{intent}.json', intent)\n",
    "    ).union(\n",
    "        load_intents(f'data/custom-intent-engines/{intent}/validate_{intent}.json', intent)\n",
    "    ))\n",
    "    # shuffle the data of the list\n",
    "    shuffle(intents_list)\n",
    "    # calculate 1/3 split\n",
    "    split = len(intents_list) // 3\n",
    "    # 1/3 of the data is used for validation\n",
    "    validation = intents_list[:split]\n",
    "    # 2/3 of the data is used for training\n",
    "    training = intents_list[split:]\n",
    "    \n",
    "    dataset[intent] = {}\n",
    "    dataset[intent]['training'] = training\n",
    "    dataset[intent]['validation'] = validation\n",
    "\n",
    "dataset = pd.DataFrame(dataset)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4bb4d8c-0435-44e6-8504-ca2162b2a5b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>utterance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8922</th>\n",
       "      <td>SearchCreativeWork</td>\n",
       "      <td>Please search the Abby saga.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>AddToPlaylist</td>\n",
       "      <td>add Rakim y Ken Y to my Gold Edition playlist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4712</th>\n",
       "      <td>PlayMusic</td>\n",
       "      <td>Play Tomtegubben Som Hade Snuva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2168</th>\n",
       "      <td>BookRestaurant</td>\n",
       "      <td>Find a reservation in Hesston NC at a new rest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831</th>\n",
       "      <td>BookRestaurant</td>\n",
       "      <td>Please book seating for one person at an indoo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  intent                                          utterance\n",
       "8922  SearchCreativeWork                       Please search the Abby saga.\n",
       "465        AddToPlaylist      add Rakim y Ken Y to my Gold Edition playlist\n",
       "4712           PlayMusic                    Play Tomtegubben Som Hade Snuva\n",
       "2168      BookRestaurant  Find a reservation in Hesston NC at a new rest...\n",
       "1831      BookRestaurant  Please book seating for one person at an indoo..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training = dataset.loc[['training']].T.explode('training').reset_index().rename(columns={\n",
    "    'index': 'intent',\n",
    "    'training': 'utterance'\n",
    "})\n",
    "training.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e71dfe4f-bdc0-4da0-9b0d-3058c1d33b23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>utterance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3048</th>\n",
       "      <td>RateBook</td>\n",
       "      <td>this essay should get 1 of the points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935</th>\n",
       "      <td>PlayMusic</td>\n",
       "      <td>I want to hear a top ten soundtrack from 1984 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3669</th>\n",
       "      <td>RateBook</td>\n",
       "      <td>Rate the current novel a 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>PlayMusic</td>\n",
       "      <td>Play some ivy anderson from around 1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036</th>\n",
       "      <td>PlayMusic</td>\n",
       "      <td>something on Spotify please</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         intent                                          utterance\n",
       "3048   RateBook              this essay should get 1 of the points\n",
       "2935  PlayMusic  I want to hear a top ten soundtrack from 1984 ...\n",
       "3669   RateBook                         Rate the current novel a 1\n",
       "2830  PlayMusic            Play some ivy anderson from around 1967\n",
       "3036  PlayMusic                        something on Spotify please"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation = dataset.loc[['validation']].T.explode('validation').reset_index().rename(columns={\n",
    "    'index': 'intent',\n",
    "    'validation': 'utterance'\n",
    "})\n",
    "validation.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab6b8589-75e7-497a-8722-e458efa1fa41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.68578712555768"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training) * 100 / (len(training) + len(validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d1ccae6-a797-4268-a832-6161298d528b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.31421287444232"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation) * 100 / (len(training) + len(validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3381086-8579-436f-a62a-08f838217720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intent              \n",
       "GetWeather              14.823664\n",
       "PlayMusic               14.775877\n",
       "BookRestaurant          14.747204\n",
       "RateBook                14.078180\n",
       "SearchCreativeWork      14.039950\n",
       "AddToPlaylist           13.896588\n",
       "SearchScreeningEvent    13.638536\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.value_counts(subset=['intent'], normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7c3aff2-500e-451a-af74-c0a27460bf5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intent              \n",
       "GetWeather              14.826861\n",
       "PlayMusic               14.769466\n",
       "BookRestaurant          14.750335\n",
       "RateBook                14.080735\n",
       "SearchCreativeWork      14.042472\n",
       "AddToPlaylist           13.889420\n",
       "SearchScreeningEvent    13.640712\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.value_counts(subset=['intent'], normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cacc15-b15e-4c1f-aa27-6f524239601f",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bc6916-8365-4e87-9417-720559d0f589",
   "metadata": {},
   "source": [
    "Create training and evaluation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43be7377-0c27-4f6a-b109-656c2d906c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "label2id = {v: k for k, v in enumerate(intents)}\n",
    "id2label = {k: v for k, v in enumerate(intents)}\n",
    "\n",
    "def encode(row):  \n",
    "    return label2id[row['intent']]\n",
    "\n",
    "train_dataset = Dataset.from_dict({\n",
    "    'text': training.utterance.to_list(),\n",
    "    'label': training.apply(encode, axis=1).to_list()\n",
    "})\n",
    "\n",
    "eval_dataset = Dataset.from_dict({\n",
    "    'text': validation.utterance.to_list(),\n",
    "    'label': validation.apply(encode, axis=1).to_list()\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fdb5cb-09d3-421b-9e3d-2007340181af",
   "metadata": {},
   "source": [
    "Load a pretrained BERT tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39f27207-e681-4b76-92fa-aa1cac9b5daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "\n",
    "BERT = 'distilbert-base-uncased'\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(BERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73443a78-8aa1-4bec-9a39-e04136dd14d4",
   "metadata": {},
   "source": [
    "Tokenize text and truncate sequences to be no longer than DistilBERTâ€™s maximum input length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18a010bc-5df5-41ad-a9e8-f7052949850b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baf542548f284544a5328facb6048994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10463 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dfcaf33a66647bdb2d07733b793250d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5227 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess(examples):\n",
    "    return tokenizer(examples['text'], truncation=True) # padding=\"max_length\"\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess, batched=True)\n",
    "eval_dataset = eval_dataset.map(preprocess, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d114d6a-98f4-4e64-ba83-ffe78796612d",
   "metadata": {},
   "source": [
    "Create a batch of examples using DataCollatorWithPadding. Itâ€™s more efficient to dynamically pad the sentences to the longest length in a batch during collation, instead of padding the whole dataset to the maximum length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "437f9b89-cf0a-4f23-9939-ba14dd7fc090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'add this track to my Gold School playlist',\n",
       " 'label': 0,\n",
       " 'input_ids': [101, 5587, 2023, 2650, 2000, 2026, 2751, 2082, 2377, 9863, 102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09d27849-04e9-49a5-8776-4ec12694dae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3930ea7-03b3-46b1-91f2-7d92abadbd5c",
   "metadata": {},
   "source": [
    "Load an evaluation method with the ðŸ¤— Evaluate library. Including a metric during training is often helpful for evaluating your modelâ€™s performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d06402f-104d-4913-9eca-c890aa88ca32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load('accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34c5326-bd5b-47cf-a160-6ad7dbca6536",
   "metadata": {},
   "source": [
    "Then create a function that passes your predictions and labels to compute to calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19b5017a-eabe-49b0-b4b6-89d4b099e7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e67ea496-2903-4d6b-a5f5-6d5c7b1565d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertConfig {\n",
       "  \"activation\": \"gelu\",\n",
       "  \"architectures\": [\n",
       "    \"DistilBertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.1,\n",
       "  \"dim\": 768,\n",
       "  \"dropout\": 0.1,\n",
       "  \"hidden_dim\": 3072,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"AddToPlaylist\",\n",
       "    \"1\": \"BookRestaurant\",\n",
       "    \"2\": \"GetWeather\",\n",
       "    \"3\": \"PlayMusic\",\n",
       "    \"4\": \"RateBook\",\n",
       "    \"5\": \"SearchCreativeWork\",\n",
       "    \"6\": \"SearchScreeningEvent\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"label2id\": {\n",
       "    \"AddToPlaylist\": 0,\n",
       "    \"BookRestaurant\": 1,\n",
       "    \"GetWeather\": 2,\n",
       "    \"PlayMusic\": 3,\n",
       "    \"RateBook\": 4,\n",
       "    \"SearchCreativeWork\": 5,\n",
       "    \"SearchScreeningEvent\": 6\n",
       "  },\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"distilbert\",\n",
       "  \"n_heads\": 12,\n",
       "  \"n_layers\": 6,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"qa_dropout\": 0.1,\n",
       "  \"seq_classif_dropout\": 0.2,\n",
       "  \"sinusoidal_pos_embds\": false,\n",
       "  \"tie_weights_\": true,\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.53.3\",\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    BERT,\n",
    "    num_labels=len(intents),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562f0ce8-ef5e-47cc-8ec7-6564dfab2a79",
   "metadata": {},
   "source": [
    "## References\n",
    "- [Create Dataset](https://huggingface.co/docs/datasets/v4.0.0/en/create_dataset)\n",
    "- [NLP quickstart](https://huggingface.co/docs/datasets/en/quickstart#nlp)\n",
    "- [Trainer API](https://huggingface.co/docs/transformers/en/main_classes/trainer)\n",
    "- [Evaluate](https://huggingface.co/docs/evaluate/a_quick_tour)\n",
    "- [Text Classification](https://huggingface.co/docs/transformers/tasks/sequence_classification)\n",
    "\n",
    "```\n",
    "import torch\n",
    "\n",
    "dataset = dataset.select_columns([\"input_ids\", \"token_type_ids\", \"attention_mask\", \"labels\"])\n",
    "dataset = dataset.with_format(type=\"torch\")\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346ea1c3-c7c0-469f-9abd-422686b36caa",
   "metadata": {},
   "source": [
    "Define the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05ff8169-c0b7-4b3c-b7bf-6fb30d02ce12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "epochs = 2\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = './models/output',\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "\n",
    "    # deep learning parameters\n",
    "    warmup_steps=len(training) // 5, # number of warmup steps for the learning rate scheduler\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=1e-5,\n",
    "\n",
    "    logging_steps=1,\n",
    "    log_level='info',\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc54c7f9-acee-411e-8345-867ebdec4459",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the Evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5227\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='328' max='164' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [164/164 01:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.9477510452270508,\n",
       " 'eval_model_preparation_time': 0.0019,\n",
       " 'eval_accuracy': 0.12511957145590205,\n",
       " 'eval_runtime': 3.3465,\n",
       " 'eval_samples_per_second': 1561.911,\n",
       " 'eval_steps_per_second': 49.006}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4446c826-5e1a-4634-b003-a5930f587864",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the Training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 10,463\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 654\n",
      "  Number of trainable parameters = 66,958,855\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [654/654 00:56, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.610800</td>\n",
       "      <td>1.586888</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.840635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.338200</td>\n",
       "      <td>0.346689</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.967094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the Evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5227\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./models/output/checkpoint-327\n",
      "Configuration saved in ./models/output/checkpoint-327/config.json\n",
      "Model weights saved in ./models/output/checkpoint-327/model.safetensors\n",
      "Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n",
      "tokenizer config file saved in ./models/output/checkpoint-327/tokenizer_config.json\n",
      "Special tokens file saved in ./models/output/checkpoint-327/special_tokens_map.json\n",
      "The following columns in the Evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5227\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./models/output/checkpoint-654\n",
      "Configuration saved in ./models/output/checkpoint-654/config.json\n",
      "Model weights saved in ./models/output/checkpoint-654/model.safetensors\n",
      "Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n",
      "tokenizer config file saved in ./models/output/checkpoint-654/tokenizer_config.json\n",
      "Special tokens file saved in ./models/output/checkpoint-654/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./models/output/checkpoint-654 (score: 0.34668880701065063).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=654, training_loss=1.410431821776457, metrics={'train_runtime': 56.9922, 'train_samples_per_second': 367.173, 'train_steps_per_second': 11.475, 'total_flos': 122946141057906.0, 'train_loss': 1.410431821776457, 'epoch': 2.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "061a4c8c-5e75-4f2d-a753-bcb0b74bc3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the Evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5227\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='164' max='164' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [164/164 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.34668880701065063,\n",
       " 'eval_model_preparation_time': 0.0019,\n",
       " 'eval_accuracy': 0.9670939353357566,\n",
       " 'eval_runtime': 2.9087,\n",
       " 'eval_samples_per_second': 1797.02,\n",
       " 'eval_steps_per_second': 56.382,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4232ccf-96b1-49e6-8b3a-49f826fab88d",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5ab2be0-6265-4344-acfd-27e359fba11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline('text-classification', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ae5a045-60c6-4323-83bd-dbe5904dd3ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'GetWeather', 'score': 0.8123217821121216}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('Is it going to be sunny tomorrow?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ab51188-60f6-4cc6-83fc-248fe79fa124",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./models/output\n",
      "Configuration saved in ./models/output/config.json\n",
      "Model weights saved in ./models/output/model.safetensors\n",
      "Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n",
      "tokenizer config file saved in ./models/output/tokenizer_config.json\n",
      "Special tokens file saved in ./models/output/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "468941e8-1def-43a1-9a1c-bcb0b455b037",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./models/output/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"AddToPlaylist\",\n",
      "    \"1\": \"BookRestaurant\",\n",
      "    \"2\": \"GetWeather\",\n",
      "    \"3\": \"PlayMusic\",\n",
      "    \"4\": \"RateBook\",\n",
      "    \"5\": \"SearchCreativeWork\",\n",
      "    \"6\": \"SearchScreeningEvent\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"AddToPlaylist\": 0,\n",
      "    \"BookRestaurant\": 1,\n",
      "    \"GetWeather\": 2,\n",
      "    \"PlayMusic\": 3,\n",
      "    \"RateBook\": 4,\n",
      "    \"SearchCreativeWork\": 5,\n",
      "    \"SearchScreeningEvent\": 6\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.53.3\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file ./models/output/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"AddToPlaylist\",\n",
      "    \"1\": \"BookRestaurant\",\n",
      "    \"2\": \"GetWeather\",\n",
      "    \"3\": \"PlayMusic\",\n",
      "    \"4\": \"RateBook\",\n",
      "    \"5\": \"SearchCreativeWork\",\n",
      "    \"6\": \"SearchScreeningEvent\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"AddToPlaylist\": 0,\n",
      "    \"BookRestaurant\": 1,\n",
      "    \"GetWeather\": 2,\n",
      "    \"PlayMusic\": 3,\n",
      "    \"RateBook\": 4,\n",
      "    \"SearchCreativeWork\": 5,\n",
      "    \"SearchScreeningEvent\": 6\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.53.3\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file ./models/output/model.safetensors\n",
      "Will use torch_dtype=torch.float32 as defined in model's config object\n",
      "Instantiating DistilBertForSequenceClassification model under default dtype torch.float32.\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at ./models/output.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline('text-classification', model='./models/output', tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "569c427a-f2ec-4f89-a45d-517ab0dd958e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'AddToPlaylist', 'score': 0.8058907389640808}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('Add Stitches by Shawn Mendes to my favourites')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5286073-e617-46d9-ab89-14b9ce2084d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'RateBook', 'score': 0.8625803589820862}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('Harry Potter was 10 out of 10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6fa54d08-f1e7-4ff0-9b31-e06fabcb644c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'BookRestaurant', 'score': 0.7580662369728088}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('Put aside a crib for 2 at 20:30 at the Sartori inn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6e66e8-6b26-4a03-92f2-eb7f136b8e5b",
   "metadata": {},
   "source": [
    "# Fine tuning by freezing BERT parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2cc2520-b50f-43ea-b350-5171363a75d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/spaccs01/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"AddToPlaylist\",\n",
      "    \"1\": \"BookRestaurant\",\n",
      "    \"2\": \"GetWeather\",\n",
      "    \"3\": \"PlayMusic\",\n",
      "    \"4\": \"RateBook\",\n",
      "    \"5\": \"SearchCreativeWork\",\n",
      "    \"6\": \"SearchScreeningEvent\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"AddToPlaylist\": 0,\n",
      "    \"BookRestaurant\": 1,\n",
      "    \"GetWeather\": 2,\n",
      "    \"PlayMusic\": 3,\n",
      "    \"RateBook\": 4,\n",
      "    \"SearchCreativeWork\": 5,\n",
      "    \"SearchScreeningEvent\": 6\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.53.3\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /Users/spaccs01/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/model.safetensors\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "frozen_model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    BERT,\n",
    "    num_labels=len(intents),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3363038a-04fa-4871-88d3-82256897d7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in frozen_model.distilbert.parameters():\n",
    "    param.requires_grad = False # freezing the parameters of the pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea45731-91ae-4249-94f6-da9f7c0a9818",
   "metadata": {},
   "source": [
    "We freeze the parameters of the pre-trained model, and then we run the fine-tuning training as before.\n",
    "The training phase will take less time to run, but the accuracy will be lower than the other fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f7fac8c-37aa-4153-a4ce-567531491a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "epochs = 2\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = './models/frozen/output',\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "\n",
    "    # deep learning parameters\n",
    "    warmup_steps=len(training) // 5, # number of warmup steps for the learning rate scheduler\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=1e-5,\n",
    "\n",
    "    logging_steps=1,\n",
    "    log_level='info',\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=frozen_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1de09d32-ae8d-4d9c-85d7-cddeec4a4acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the Evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5227\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='328' max='164' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [164/164 00:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.9417152404785156,\n",
       " 'eval_model_preparation_time': 0.0019,\n",
       " 'eval_accuracy': 0.1811746699827817,\n",
       " 'eval_runtime': 2.9131,\n",
       " 'eval_samples_per_second': 1794.338,\n",
       " 'eval_steps_per_second': 56.298}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "121cd3ef-7521-4246-b64e-9ba8370e4fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the Training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 10,463\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 654\n",
      "  Number of trainable parameters = 595,975\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [654/654 00:19, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.955100</td>\n",
       "      <td>1.925956</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.236656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.859100</td>\n",
       "      <td>1.876852</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.458389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the Evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5227\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./models/frozen/output/checkpoint-327\n",
      "Configuration saved in ./models/frozen/output/checkpoint-327/config.json\n",
      "Model weights saved in ./models/frozen/output/checkpoint-327/model.safetensors\n",
      "Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n",
      "tokenizer config file saved in ./models/frozen/output/checkpoint-327/tokenizer_config.json\n",
      "Special tokens file saved in ./models/frozen/output/checkpoint-327/special_tokens_map.json\n",
      "The following columns in the Evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5227\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./models/frozen/output/checkpoint-654\n",
      "Configuration saved in ./models/frozen/output/checkpoint-654/config.json\n",
      "Model weights saved in ./models/frozen/output/checkpoint-654/model.safetensors\n",
      "Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n",
      "tokenizer config file saved in ./models/frozen/output/checkpoint-654/tokenizer_config.json\n",
      "Special tokens file saved in ./models/frozen/output/checkpoint-654/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./models/frozen/output/checkpoint-654 (score: 1.87685227394104).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=654, training_loss=1.9238947165121727, metrics={'train_runtime': 19.4954, 'train_samples_per_second': 1073.38, 'train_steps_per_second': 33.546, 'total_flos': 122946141057906.0, 'train_loss': 1.9238947165121727, 'epoch': 2.0})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a003b22-949f-4001-bd82-bfe4a2b6afb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline('text-classification', model=frozen_model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "41163738-6d75-4edd-bfc4-0d0451238caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'AddToPlaylist', 'score': 0.161112979054451}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('Add Stitches by Shawn Mendes to my favourites')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "100c213b-86e8-4aa7-b2b6-ca4961dba0ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'BookRestaurant', 'score': 0.16327163577079773}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('Put aside a crib for 2 at 20:30 at the Sartori inn')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
