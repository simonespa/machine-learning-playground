{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03ecc572",
   "metadata": {},
   "source": [
    "# Housing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "199c8cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 14 columns):\n",
      " #   Column                    Non-Null Count  Dtype   \n",
      "---  ------                    --------------  -----   \n",
      " 0   longitude                 20640 non-null  float32 \n",
      " 1   latitude                  20640 non-null  float32 \n",
      " 2   housing_median_age        20640 non-null  uint8   \n",
      " 3   total_rooms               20640 non-null  float64 \n",
      " 4   total_bedrooms            20433 non-null  float64 \n",
      " 5   population                20640 non-null  uint16  \n",
      " 6   households                20640 non-null  uint16  \n",
      " 7   median_income             20640 non-null  float32 \n",
      " 8   median_house_value        20640 non-null  float32 \n",
      " 9   ocean_proximity           20640 non-null  category\n",
      " 10  median_income_categories  20640 non-null  category\n",
      " 11  rooms_per_household       20640 non-null  float64 \n",
      " 12  bedrooms_per_room         20433 non-null  float64 \n",
      " 13  population_per_household  20640 non-null  float64 \n",
      "dtypes: category(2), float32(4), float64(5), uint16(2), uint8(1)\n",
      "memory usage: 1.2 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# https://numpy.org/doc/stable/reference/arrays.scalars.html\n",
    "# https://numpy.org/doc/stable/reference/arrays.dtypes.html\n",
    "# https://www.bbc.co.uk/bitesize/guides/zscvxfr/revision/3\n",
    "\n",
    "# I'm type casting the data to save space in memory.\n",
    "# Although the full CSV it's just ~1MB, it's generally useful to set a fitting type for each attribute.\n",
    "housing = pd.read_csv(\n",
    "    'housing.csv',\n",
    "    dtype={\n",
    "        'longitude': np.float32,\n",
    "        'latitude': np.float32,\n",
    "        'housing_median_age': np.uint8,\n",
    "        'population': np.uint16,\n",
    "        'households': np.uint16,\n",
    "        'median_income': np.float32,\n",
    "        'median_house_value': np.float32,\n",
    "        'ocean_proximity': 'category'\n",
    "    }\n",
    ")\n",
    "\n",
    "housing = housing.assign(\n",
    "    # used to create stratified sampling for the training and test set\n",
    "    median_income_categories = pd.cut(\n",
    "        housing['median_income'],\n",
    "        bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "        labels=[1, 2, 3, 4, 5]\n",
    "    ),\n",
    "    rooms_per_household = housing[\"total_rooms\"] / housing[\"households\"],\n",
    "    bedrooms_per_room = housing[\"total_bedrooms\"] / housing[\"total_rooms\"],\n",
    "    population_per_household = housing[\"population\"] / housing[\"households\"]\n",
    ")\n",
    "housing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fbc29b",
   "metadata": {},
   "source": [
    "## Training and Test split\n",
    "\n",
    "Split the Training and the Test sets baed on the `median_income_categories` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a0dd3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, test_index in split.split(housing, housing['median_income_categories']):\n",
    "    train_set = housing.loc[train_index]\n",
    "    test_set = housing.loc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e91622",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Remove the labels from the other attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "995e6f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_set.drop('median_house_value', axis=1)\n",
    "y_train = train_set[['median_house_value']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51703fc8",
   "metadata": {},
   "source": [
    "Separate the numerical from the categorical attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f48cc133",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attributes = housing.drop(['ocean_proximity', 'median_income_categories', 'median_house_value'], axis=1).columns\n",
    "cat_attributes = housing[['ocean_proximity']].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "352b9827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.94135   ,  1.34743845,  0.02756357, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.17178042, -1.19243959, -1.72201763, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.26758072, -0.1259721 ,  1.22045984, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-1.5707948 ,  1.31001766,  1.53856552, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.5608015 ,  1.24921155, -1.1653327 , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.28104994,  2.02567507, -0.13148926, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('encoder', OneHotEncoder())\n",
    "])\n",
    "\n",
    "pipeline = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_attributes),\n",
    "    ('cat', cat_pipeline, cat_attributes)\n",
    "])\n",
    "\n",
    "pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cf2642",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
