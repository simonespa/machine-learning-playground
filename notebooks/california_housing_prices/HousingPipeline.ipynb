{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03ecc572",
   "metadata": {},
   "source": [
    "# Housing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "199c8cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# https://numpy.org/doc/stable/reference/arrays.scalars.html\n",
    "# https://numpy.org/doc/stable/reference/arrays.dtypes.html\n",
    "# https://www.bbc.co.uk/bitesize/guides/zscvxfr/revision/3\n",
    "\n",
    "# I'm type casting the data to save space in memory.\n",
    "# Although the full CSV it's just ~1MB, it's generally useful to set the right type for each attribute.\n",
    "housing = pd.read_csv(\n",
    "    'housing.csv',\n",
    "    dtype={\n",
    "        'longitude': np.float32,\n",
    "        'latitude': np.float32,\n",
    "        'housing_median_age': np.uint8,\n",
    "        'population': np.uint16,\n",
    "        'households': np.uint16,\n",
    "        'median_income': np.float32,\n",
    "        'median_house_value': np.float32,\n",
    "        'ocean_proximity': 'category'\n",
    "    }\n",
    ")\n",
    "\n",
    "housing = housing.assign(\n",
    "    # used to create stratified sampling for the training and test set\n",
    "    median_income_categories = pd.cut(\n",
    "        housing['median_income'],\n",
    "        bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "        labels=[1, 2, 3, 4, 5]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fbc29b",
   "metadata": {},
   "source": [
    "## Training, Validation and Test split\n",
    "\n",
    "Split the original dataset in 3 subsets in order to generate the Training, Validation and Test sets, stratifying the samples baed on the `median_income_categories` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2a0dd3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for training_index, test_index in split.split(housing, housing['median_income_categories']):\n",
    "    training_set = housing.loc[training_index]\n",
    "    test_set = housing.loc[test_index]\n",
    "\n",
    "for training_index, validation_index in split.split(training_set, training_set['median_income_categories']):\n",
    "    training_set = housing.loc[training_index]\n",
    "    validation_set = housing.loc[validation_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904a50e5",
   "metadata": {},
   "source": [
    "Separate the label attribute from the rest of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a42db49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training = training_set.drop('median_house_value', axis=1)\n",
    "y_training = training_set[['median_house_value']].copy()\n",
    "\n",
    "X_validation = validation_set.drop('median_house_value', axis=1)\n",
    "y_validation = validation_set[['median_house_value']].copy()\n",
    "\n",
    "X_test = test_set.drop('median_house_value', axis=1)\n",
    "y_test = test_set[['median_house_value']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e91622",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5b2fe0",
   "metadata": {},
   "source": [
    "Create a custom transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7f7882c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class FeaturesAdder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X['rooms_per_household'] = X['total_rooms'] / X['households']\n",
    "        X['bedrooms_per_room'] = X['total_bedrooms'] / X['total_rooms']\n",
    "        X['population_per_household'] = X['population'] / X['households']\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51703fc8",
   "metadata": {},
   "source": [
    "List numerical and categorical attribute names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f48cc133",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'median_house_value'\n",
    "\n",
    "num_attributes = np.array(housing.drop([\n",
    "    'ocean_proximity', # categorical\n",
    "    'median_income_categories', # categorical\n",
    "    label\n",
    "], axis=1).columns)\n",
    "\n",
    "num_attributes = np.append(num_attributes, ['rooms_per_household', 'bedrooms_per_room', 'population_per_household'])\n",
    "\n",
    "cat_attributes = ['ocean_proximity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "352b9827",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('encoder', OneHotEncoder())\n",
    "])\n",
    "\n",
    "column_transformer = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_attributes),\n",
    "    ('cat', cat_pipeline, cat_attributes),\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features_adder', FeaturesAdder()),\n",
    "    ('column_transformer', column_transformer)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3a7e36",
   "metadata": {},
   "source": [
    "Transform the **Training** set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "13a6c4ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.74245559,  1.19599336,  1.53645742, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [ 0.9497955 , -0.99423992, -1.04712607, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-1.62811225,  1.23903297,  1.77132865, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.49762065, -0.53993333,  1.14500538, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.20712447,  1.61682491, -0.73396443, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.47948829,  1.79376472, -0.81225484, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit_transform(X_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4c15c1",
   "metadata": {},
   "source": [
    "Fit and predict with **Linear Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c6cf2642",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[1;32m      3\u001b[0m lin_reg \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[0;32m----> 4\u001b[0m regression \u001b[38;5;241m=\u001b[39m \u001b[43mlin_reg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_training\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_training\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/playground/machine-learning-playground/.env/lib/python3.10/site-packages/sklearn/linear_model/_base.py:649\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    645\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[1;32m    647\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 649\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    651\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(\n\u001b[1;32m    654\u001b[0m     sample_weight, X, dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype, only_non_negative\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    655\u001b[0m )\n\u001b[1;32m    657\u001b[0m X, y, X_offset, y_offset, X_scale \u001b[38;5;241m=\u001b[39m _preprocess_data(\n\u001b[1;32m    658\u001b[0m     X,\n\u001b[1;32m    659\u001b[0m     y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    662\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    663\u001b[0m )\n",
      "File \u001b[0;32m~/workspace/playground/machine-learning-playground/.env/lib/python3.10/site-packages/sklearn/base.py:554\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    552\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 554\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    555\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/workspace/playground/machine-learning-playground/.env/lib/python3.10/site-packages/sklearn/utils/validation.py:1104\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1099\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1102\u001b[0m     )\n\u001b[0;32m-> 1104\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1120\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1122\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/workspace/playground/machine-learning-playground/.env/lib/python3.10/site-packages/sklearn/utils/validation.py:919\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    914\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    915\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    916\u001b[0m         )\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 919\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    927\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/workspace/playground/machine-learning-playground/.env/lib/python3.10/site-packages/sklearn/utils/validation.py:111\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _object_dtype_isnan(X)\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m--> 111\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput contains NaN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# We need only consider float arrays, hence can early return for all else.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "regression = lin_reg.fit(X_training, y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b95f91b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6317681030307358"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression.score(X_training_transformed, y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "98d4cc79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-52221.01888317, -55344.85860461,  14084.95498277,\n",
       "          4117.06747897,   8561.7460345 , -46797.984934  ,\n",
       "         39549.15601785,  77616.54636622,   7161.98914326,\n",
       "         17331.92509365,    322.77703972, -16002.40424786,\n",
       "        -50249.31984802, 106084.38909803, -20456.50023774,\n",
       "        -19376.16476442]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f03f747e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([229671.22666063])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e8876bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = regression.predict(X_validation_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "13ce453b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67511.67216078292"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lin_mse = mean_squared_error(y_validation, predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8bceb2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(X_training_transformed, y_training)\n",
    "tree_reg.score(X_training_transformed, y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "95affd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_predictions = tree_reg.predict(X_validation_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef66583d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97953.89241777746"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_mse = mean_squared_error(y_validation, tree_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace487a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
