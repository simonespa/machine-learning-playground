# Retentive networks

Start with introduction
- Software engineer
- Recently started with a DataScience apprenticeship

Introduce the impossible Triangle to set the context. What are people trying to do? Why are they still trying to improve upon Transformers?

Briefly summarise the evolution of transformers from LSTM-based Encoder-Decoder Architecture, then Transformers, now with something else.
- What was the problem with RNN/LSTMs?
- What is the problem with Transformers?
- How is RetNet addressing this problem?

Introduce RetNet


Introduce the impossible triangle, what is it?
Introduce the state of the art
What was there befor that?



## References
https://medium.com/ai-fusion-labs/retentive-networks-retnet-explained-the-much-awaited-transformers-killer-is-here-6c17e3e8add8
